\begin{slide}[\slideopts,toc={}]{Abstract}

Today's sequence models (such as large language models) in machine
learning (AI) arose from a blend of principle-based design and
empirical discovery, spanning several fields.
\maybepause
This talk describes how the ideas could have emerged from an elementary signal-processing
approach.
\maybepause
This viewpoint offers some features:
\begin{enumerate}
\mpitem Signal processing folks can quickly learn what is happening in a motivated way
\mpitem Machine-learning experts might benefit from signal-processing insights
\mpitem Obvious suggestions for things to try next naturally arise
\end{enumerate}

% \href{https://ccrma.stanford.edu/ccrma-open-house}{[Open House Schedule]}

%\textbf{Overheads and more:} \href{https://ccrma.stanford.edu/~jos/Welcome.html#dsponline24}{https://ccrma.stanford.edu/\~{}jos/Welcome.html\#dsponline24}
%\textbf{Overheads and more:} \href{https://ccrma.stanford.edu/~jos/Welcome.html#dsponline24}{https://ccrma.stanford.edu/~jos/Welcome.html#dsponline24}

\end{slide}
